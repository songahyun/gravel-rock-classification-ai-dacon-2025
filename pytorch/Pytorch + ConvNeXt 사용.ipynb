{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98237b89-cb80-43f9-b313-8728c0e635db",
   "metadata": {},
   "source": [
    "## Pytorch + ConvNeXt 첫 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "397296d2-fbe2-457d-9f89-01a95f99876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "\n",
    "# 설정\n",
    "train_dir = 'open/train'\n",
    "test_csv_path = 'open/test.csv'\n",
    "output_dir = 'pytorch_timm_output2'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cda2d68a-e403-4170-b7ad-4f6091333b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOR\\AppData\\Local\\Temp\\ipykernel_7348\\224301924.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_balanced = df.groupby('label').apply(lambda x: x.sample(n=10000, random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터 구성\n",
    "df = pd.DataFrame({'image': list(Path(train_dir).rglob(\"*/*.jpg\"))})\n",
    "df['label'] = df['image'].apply(lambda x: x.parent.name)\n",
    "df['image'] = df['image'].astype(str)\n",
    "\n",
    "# 라벨 인코딩\n",
    "label2idx = {label: idx for idx, label in enumerate(sorted(df['label'].unique()))}\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}\n",
    "df['label_idx'] = df['label'].map(label2idx)\n",
    "\n",
    "# 데이터 샘플링 (폴더별 10,000장)\n",
    "df_balanced = df.groupby('label').apply(lambda x: x.sample(n=10000, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "# train/val 분리\n",
    "train_df, val_df = train_test_split(df_balanced, test_size=0.3, stratify=df_balanced['label_idx'], random_state=42)\n",
    "\n",
    "# 커스텀 Dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['image']\n",
    "        label = self.df.iloc[idx]['label_idx']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# 이미지 변환\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# 데이터로더\n",
    "train_dataset = ImageDataset(train_df, transform=transform)\n",
    "val_dataset = ImageDataset(val_df, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d79215e-1833-4113-928e-88cc6b0f900d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8e23ea28484851ba8109504fdedfed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/354M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOR\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\FOR\\.cache\\huggingface\\hub\\models--timm--convnext_base.fb_in22k_ft_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정 - ConvNeXt로 변경\n",
    "model = timm.create_model('convnext_base', pretrained=True, num_classes=len(label2idx))\n",
    "model.to(device)\n",
    "\n",
    "# 손실 함수와 옵티마이저\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 학습 루프\n",
    "num_epochs = 7\n",
    "best_acc = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc24e74-9829-4e43-b515-815c22fe4bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 224, 224]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8555b59a-bdd3-4c34-9afd-49863d9aef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/7: 100%|███████████████████████████████████████████████████████████████████| 3063/3063 [51:08<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7296\n",
      "Val Accuracy: 78.43%\n",
      "✅ 모델 저장 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/7: 100%|███████████████████████████████████████████████████████████████████| 3063/3063 [51:17<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4555\n",
      "Val Accuracy: 79.76%\n",
      "✅ 모델 저장 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/7: 100%|███████████████████████████████████████████████████████████████████| 3063/3063 [51:11<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2326\n",
      "Val Accuracy: 80.41%\n",
      "✅ 모델 저장 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/7: 100%|███████████████████████████████████████████████████████████████████| 3063/3063 [51:44<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1037\n",
      "Val Accuracy: 77.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/7: 100%|███████████████████████████████████████████████████████████████████| 3063/3063 [49:18<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0753\n",
      "Val Accuracy: 80.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/7: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3063/3063 [49:07<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0611\n",
      "Val Accuracy: 79.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/7: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3063/3063 [49:04<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0538\n",
      "Val Accuracy: 80.10%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Train Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # 검증\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"Val Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), os.path.join(output_dir, 'best_model.pth'))\n",
    "        print(\"✅ 모델 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eb20e2c-5322-40f4-92eb-9c74afd8b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 예측\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['img_path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "test_df['img_path'] = test_df['img_path'].apply(lambda x: os.path.join('open', x))\n",
    "\n",
    "test_dataset = TestDataset(test_df, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7220d8d-3ac6-4af1-b3b3-1ea3b3efd761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 제출 파일 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "model.load_state_dict(torch.load(os.path.join(output_dir, 'best_model.pth')))\n",
    "model.eval()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "# 라벨 복원 및 제출 파일 생성\n",
    "submission = pd.read_csv('open/sample_submission.csv')\n",
    "submission['rock_type'] = [idx2label[p] for p in preds]\n",
    "submission.to_csv('submission_timm2.csv', index=False)\n",
    "print(\"🎉 제출 파일 저장 완료!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449aba5a-3fa9-47a8-945b-9460806f4283",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd588180-8303-4eab-bb7a-fd018ddfb92b",
   "metadata": {},
   "source": [
    "### 전체 코드"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c1c1e13-0672-47dc-a42d-7f5aa82094ff",
   "metadata": {},
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "\n",
    "# 설정\n",
    "train_dir = 'open/train'\n",
    "test_csv_path = 'open/test.csv'\n",
    "output_dir = 'pytorch_timm_output2'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 학습 데이터 구성\n",
    "df = pd.DataFrame({'image': list(Path(train_dir).rglob(\"*/*.jpg\"))})\n",
    "df['label'] = df['image'].apply(lambda x: x.parent.name)\n",
    "df['image'] = df['image'].astype(str)\n",
    "\n",
    "# 라벨 인코딩\n",
    "label2idx = {label: idx for idx, label in enumerate(sorted(df['label'].unique()))}\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}\n",
    "df['label_idx'] = df['label'].map(label2idx)\n",
    "\n",
    "# 데이터 샘플링 (폴더별 10,000장)\n",
    "df_balanced = df.groupby('label').apply(lambda x: x.sample(n=10000, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "# train/val 분리\n",
    "train_df, val_df = train_test_split(df_balanced, test_size=0.3, stratify=df_balanced['label_idx'], random_state=42)\n",
    "\n",
    "# 커스텀 Dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['image']\n",
    "        label = self.df.iloc[idx]['label_idx']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# 이미지 변환\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# 데이터로더\n",
    "train_dataset = ImageDataset(train_df, transform=transform)\n",
    "val_dataset = ImageDataset(val_df, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "# 모델 설정 - ConvNeXt로 변경\n",
    "model = timm.create_model('convnext_base', pretrained=True, num_classes=len(label2idx))\n",
    "model.to(device)\n",
    "\n",
    "# 손실 함수와 옵티마이저\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 학습 루프\n",
    "num_epochs = 7\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Train Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # 검증\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"Val Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), os.path.join(output_dir, 'best_model.pth'))\n",
    "        print(\"✅ 모델 저장 완료\")\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['img_path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "test_df['img_path'] = test_df['img_path'].apply(lambda x: os.path.join('open', x))\n",
    "\n",
    "test_dataset = TestDataset(test_df, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "# 예측\n",
    "model.load_state_dict(torch.load(os.path.join(output_dir, 'best_model.pth')))\n",
    "model.eval()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "# 라벨 복원 및 제출 파일 생성\n",
    "submission = pd.read_csv('open/sample_submission.csv')\n",
    "submission['rock_type'] = [idx2label[p] for p in preds]\n",
    "submission.to_csv('submission_timm2.csv', index=False)\n",
    "print(\"🎉 제출 파일 저장 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea290a44-fe83-476e-86e7-2a37b056df0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae4d96-5419-440e-ace0-30c745e04ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c3b4a1d-66d0-45a4-92e2-dde3b958d35c",
   "metadata": {},
   "source": [
    "Pytorch: 딥러닝 프레임워크\n",
    "timm: 모델 저장소. 다양한 SOTA 모델을 불러올 수 있는 pytorch 확장 라이브러리\n",
    "EfficientNet: 모델 이름. B0 ~ B7 까지 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5f3233-8b0d-4414-b8ea-924dcf82963c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
