{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98237b89-cb80-43f9-b313-8728c0e635db",
   "metadata": {},
   "source": [
    "## Pytorch + EfficientNet 첫 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "397296d2-fbe2-457d-9f89-01a95f99876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "\n",
    "# 설정\n",
    "train_dir = 'open/train'\n",
    "test_csv_path = 'open/test.csv'\n",
    "output_dir = 'pytorch_timm_output1'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cda2d68a-e403-4170-b7ad-4f6091333b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOR\\AppData\\Local\\Temp\\ipykernel_19272\\3580111058.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_balanced = df.groupby('label').apply(lambda x: x.sample(n=10000, random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터 구성\n",
    "df = pd.DataFrame({'image': list(Path(train_dir).rglob(\"*/*.jpg\"))})\n",
    "df['label'] = df['image'].apply(lambda x: x.parent.name)\n",
    "df['image'] = df['image'].astype(str)\n",
    "\n",
    "# 라벨 인코딩\n",
    "label2idx = {label: idx for idx, label in enumerate(sorted(df['label'].unique()))}\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}\n",
    "df['label_idx'] = df['label'].map(label2idx)\n",
    "\n",
    "# 데이터 샘플링 (폴더별 10,000장)\n",
    "df_balanced = df.groupby('label').apply(lambda x: x.sample(n=10000, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "# train/val 분리\n",
    "train_df, val_df = train_test_split(df_balanced, test_size=0.3, stratify=df_balanced['label_idx'], random_state=42)\n",
    "\n",
    "# 커스텀 Dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['image']\n",
    "        label = self.df.iloc[idx]['label_idx']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# 이미지 변환\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# 데이터로더\n",
    "train_dataset = ImageDataset(train_df, transform=transform)\n",
    "val_dataset = ImageDataset(val_df, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d79215e-1833-4113-928e-88cc6b0f900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설정\n",
    "model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=len(label2idx))\n",
    "model.to(device)\n",
    "\n",
    "# 손실 함수와 옵티마이저\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 학습 루프\n",
    "num_epochs = 15\n",
    "best_acc = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc24e74-9829-4e43-b515-815c22fe4bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9cf6c8d-fa04-4aee-98a2-75cef03f66d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|██████████████████████████████████████████████████████████████████| 1532/1532 [10:18<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1061\n",
      "Val Accuracy: 72.70%\n",
      "✅ 모델 저장 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|██████████████████████████████████████████████████████████████████| 1532/1532 [10:14<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6197\n",
      "Val Accuracy: 75.52%\n",
      "✅ 모델 저장 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|██████████████████████████████████████████████████████████████████| 1532/1532 [10:11<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4268\n",
      "Val Accuracy: 75.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|██████████████████████████████████████████████████████████████████| 1532/1532 [10:10<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2656\n",
      "Val Accuracy: 75.96%\n",
      "✅ 모델 저장 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|██████████████████████████████████████████████████████████████████| 1532/1532 [10:02<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1622\n",
      "Val Accuracy: 75.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|██████████████████████████████████████████████████████████████████| 1532/1532 [10:02<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1118\n",
      "Val Accuracy: 76.02%\n",
      "✅ 모델 저장 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|██████████████████████████████████████████████████████████████████| 1532/1532 [10:03<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0908\n",
      "Val Accuracy: 76.53%\n",
      "✅ 모델 저장 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100%|██████████████████████████████████████████████████████████████████| 1532/1532 [10:06<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0755\n",
      "Val Accuracy: 75.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100%|██████████████████████████████████████████████████████████████████| 1532/1532 [09:56<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0662\n",
      "Val Accuracy: 75.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 100%|█████████████████████████████████████████████████████████████████| 1532/1532 [09:55<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0587\n",
      "Val Accuracy: 76.59%\n",
      "✅ 모델 저장 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 100%|█████████████████████████████████████████████████████████████████| 1532/1532 [09:54<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0544\n",
      "Val Accuracy: 77.14%\n",
      "✅ 모델 저장 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: 100%|█████████████████████████████████████████████████████████████████| 1532/1532 [09:50<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0514\n",
      "Val Accuracy: 76.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: 100%|█████████████████████████████████████████████████████████████████| 1532/1532 [09:48<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0473\n",
      "Val Accuracy: 76.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: 100%|█████████████████████████████████████████████████████████████████| 1532/1532 [09:49<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0447\n",
      "Val Accuracy: 76.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|█████████████████████████████████████████████████████████████████| 1532/1532 [09:43<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0412\n",
      "Val Accuracy: 76.43%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Train Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # 검증\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"Val Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), os.path.join(output_dir, 'best_model.pth'))\n",
    "        print(\"✅ 모델 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0d40c87-7030-405e-ae57-96b140959c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 제출 파일 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 예측\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['img_path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "test_df['img_path'] = test_df['img_path'].apply(lambda x: os.path.join('open', x))\n",
    "\n",
    "test_dataset = TestDataset(test_df, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "# 예측\n",
    "model.load_state_dict(torch.load(os.path.join(output_dir, 'best_model.pth')))\n",
    "model.eval()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        preds.extend(predicted.cpu().numpy())\n",
    "        \n",
    "# 라벨 복원 및 제출 파일 생성\n",
    "submission = pd.read_csv('open/sample_submission.csv')\n",
    "submission['rock_type'] = [idx2label[p] for p in preds]\n",
    "submission.to_csv('submission_timm1.csv', index=False)\n",
    "print(\"🎉 제출 파일 저장 완료!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a3795-8022-4a5c-a07a-bd98c29b91ab",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e141c1-2227-489b-a7ea-f52b0cad69ed",
   "metadata": {},
   "source": [
    "### 전체 코드"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c1c1e13-0672-47dc-a42d-7f5aa82094ff",
   "metadata": {},
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "\n",
    "# 설정\n",
    "train_dir = 'open/train'\n",
    "test_csv_path = 'open/test.csv'\n",
    "output_dir = 'pytorch_timm_output2'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 학습 데이터 구성\n",
    "df = pd.DataFrame({'image': list(Path(train_dir).rglob(\"*/*.jpg\"))})\n",
    "df['label'] = df['image'].apply(lambda x: x.parent.name)\n",
    "df['image'] = df['image'].astype(str)\n",
    "\n",
    "# 라벨 인코딩\n",
    "label2idx = {label: idx for idx, label in enumerate(sorted(df['label'].unique()))}\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}\n",
    "df['label_idx'] = df['label'].map(label2idx)\n",
    "\n",
    "# 데이터 샘플링 (폴더별 10,000장)\n",
    "df_balanced = df.groupby('label').apply(lambda x: x.sample(n=10000, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "# train/val 분리\n",
    "train_df, val_df = train_test_split(df_balanced, test_size=0.3, stratify=df_balanced['label_idx'], random_state=42)\n",
    "\n",
    "# 커스텀 Dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['image']\n",
    "        label = self.df.iloc[idx]['label_idx']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# 이미지 변환\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# 데이터로더\n",
    "train_dataset = ImageDataset(train_df, transform=transform)\n",
    "val_dataset = ImageDataset(val_df, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "# 모델 설정\n",
    "model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=len(label2idx))\n",
    "model.to(device)\n",
    "\n",
    "# 손실 함수와 옵티마이저\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 학습 루프\n",
    "num_epochs = 7\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Train Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # 검증\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"Val Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), os.path.join(output_dir, 'best_model.pth'))\n",
    "        print(\"✅ 모델 저장 완료\")\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['img_path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "test_dataset = TestDataset(test_df, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "# 예측\n",
    "model.load_state_dict(torch.load(os.path.join(output_dir, 'best_model.pth')))\n",
    "model.eval()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "# 라벨 복원 및 제출 파일 생성\n",
    "submission = pd.read_csv('open/sample_submission.csv')\n",
    "submission['rock_type'] = [idx2label[p] for p in preds]\n",
    "submission.to_csv('submission_timm2.csv', index=False)\n",
    "print(\"🎉 제출 파일 저장 완료!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
