{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "784857b9-112c-48f0-8c9b-1fd5f6b7e048",
   "metadata": {},
   "source": [
    "## Autogluon 2ë²ˆì§¸ ì‹œë„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d913639f-5705-4128-87b4-c274a1626423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# ì„¤ì •\n",
    "train_dir = 'open/train'\n",
    "test_csv_path = 'open/test.csv'\n",
    "output_dir = 'autogluon_output_best2'\n",
    "resume = True  # Trueë¡œ ë‘ë©´ ì¤‘ë‹¨ í›„ ì´ì–´ì„œ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30d18c73-2fe9-4d07-984e-0e4aef5c539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. í•™ìŠµ ë°ì´í„° êµ¬ì„±\n",
    "all_img_paths = list(Path(train_dir).rglob(\"*/*.jpg\"))\n",
    "df = pd.DataFrame({'img_path': [str(p) for p in all_img_paths]})\n",
    "df['label'] = df['img_path'].apply(lambda x: Path(x).parent.name)\n",
    "df = df.rename(columns={'img_path': 'image'})  # ì»¬ëŸ¼ëª… ë³€ê²½\n",
    "\n",
    "# 2. ê° í´ë”ì—ì„œ 7ì²œ ì¥ì˜ ë°ì´í„°ë¥¼ ëœë¤ ì¶”ì¶œ\n",
    "df_balanced = pd.DataFrame()\n",
    "for label in df['label'].unique():\n",
    "    label_df = df[df['label'] == label]\n",
    "    label_df_sampled = label_df.sample(n=7000, random_state=41)\n",
    "    df_balanced = pd.concat([df_balanced, label_df_sampled], axis=0)\n",
    "\n",
    "# 3. train/val ë¶„ë¦¬\n",
    "train_df, val_df = train_test_split(df_balanced, test_size=0.3, stratify=df_balanced['label'], random_state=41)\n",
    "train_df_small = train_df.sample(n=min(49000, len(train_df)), random_state=41)\n",
    "val_df_small = val_df.sample(n=min(15000, len(val_df)), random_state=41)\n",
    "\n",
    "# # 4. GPU ì„¤ì •\n",
    "# num_gpus = 1 if torch.cuda.is_available() else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7d0475b-89e4-4223-baf7-b3bcc24d6aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ†• ìƒˆë¡œìš´ predictorë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ê¸°ì¡´ predictor ë¶ˆëŸ¬ì˜¤ê¸° ë˜ëŠ” ìƒˆë¡œ ìƒì„±\n",
    "if resume and os.path.exists(os.path.join(output_dir, 'predictor.pkl')):\n",
    "    print(\"ğŸ” ì´ì „ í•™ìŠµ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\")\n",
    "    predictor = MultiModalPredictor.load(output_dir)\n",
    "else:\n",
    "    print(\"ğŸ†• ìƒˆë¡œìš´ predictorë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
    "    predictor = MultiModalPredictor(\n",
    "        label='label',\n",
    "        problem_type='classification',\n",
    "        path=output_dir\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eda4714-35f3-44db-b114-c729bc0ba252",
   "metadata": {},
   "source": [
    "### í•™ìŠµ ì¤‘ê°„ì— ì£¼í”¼í„° ë…¸íŠ¸ë¶ì´ ì¢…ë£Œë¨(ê°•ì œì¢…ë£Œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834f9af3-a6d5-44bc-8388-8bb2ef34eb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.11.1\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          6\n",
      "Pytorch Version:    2.6.0+cu126\n",
      "CUDA Version:       12.6\n",
      "Memory Avail:       18.39 GB / 23.91 GB (76.9%)\n",
      "Disk Space Avail:   35.01 GB / 222.28 GB (15.7%)\n",
      "===================================================\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t7 unique label values:  ['Andesite', 'Basalt', 'Mud_Sandstone', 'Etc', 'Gneiss', 'Weathered_Rock', 'Granite']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "\n",
      "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir C:\\Users\\FOR\\Deep Learning\\autogluon_output_best2\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 95.7 M | train\n",
      "1 | validation_metric | MulticlassAccuracy              | 0      | train\n",
      "2 | loss_func         | CrossEntropyLoss                | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "95.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "95.7 M    Total params\n",
      "382.808   Total estimated model params size (MB)\n",
      "863       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d75cdfa5d2f4841aec77577c0d17506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2dd218c654049fb86a0f70312a0c6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02bb1839fa4c4e4c956134a04d256839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 134: 'val_accuracy' reached 0.14286 (best 0.14286), saving model to 'C:\\\\Users\\\\FOR\\\\Deep Learning\\\\autogluon_output_best2\\\\epoch=0-step=134.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105c61933af14e8b8a7890405faea49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 268: 'val_accuracy' reached 0.14286 (best 0.14286), saving model to 'C:\\\\Users\\\\FOR\\\\Deep Learning\\\\autogluon_output_best2\\\\epoch=0-step=268.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "927b94d1443a4dc7832e592444f4e45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 402: 'val_accuracy' reached 0.14286 (best 0.14286), saving model to 'C:\\\\Users\\\\FOR\\\\Deep Learning\\\\autogluon_output_best2\\\\epoch=1-step=402.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee87726cae14b34960731fb8198eb6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 536: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dafcd4bbe59348938d5be22a1ac0efc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 670: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91018384ebbd416fa81aab1b16a7848e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 804: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1543db29b524493a9fe226d9cacaf27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 938: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033d4f82ec084cb68073eaf73a3d67c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 1072: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07af81e69d4244dcb20029d0b5cb66c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1206: 'val_accuracy' was not in top 3\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'model': {\n",
    "        'max_epochs': 3  # ì›í•˜ëŠ” ì—í¬í¬ ìˆ˜ ì§€ì •\n",
    "    }\n",
    "}\n",
    "\n",
    "# 6. í•™ìŠµ ì‹œì‘ (ë‚¨ì€ ì—í¬í¬ë§Œí¼)\n",
    "predictor.fit(\n",
    "    train_data=train_df_small,\n",
    "    tuning_data=val_df_small,\n",
    "    hyperparameters=hyperparameters,\n",
    "    hyperparameter_tune_kwargs=None,\n",
    "    presets='high_quality',\n",
    "    # num_gpus=num_gpus  # ì—¬ê¸°ì„œ GPU ê°œìˆ˜ ì§€ì •\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7de607a-0c1a-469c-9dc5-2b0e39256b3a",
   "metadata": {},
   "source": [
    "### í•™ìŠµ ì¬ê°œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fda2df4b-627b-449d-a162-edb492a3fc5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MultiModalPredictor.fit() got an unexpected keyword argument 'resume'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m predictor = MultiModalPredictor(\n\u001b[32m      2\u001b[39m     label=\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m     problem_type=\u001b[33m'\u001b[39m\u001b[33mclassification\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      4\u001b[39m     path=\u001b[33m'\u001b[39m\u001b[33mC:/Users/FOR/Deep Learning/autogluon_output_best2\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      5\u001b[39m )\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# ì´ì–´ì„œ í•™ìŠµ (checkpoint ìë™ ê°ì§€)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtuning_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmax_epochs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpresets\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhigh_quality\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3600\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ë°˜ë“œì‹œ í•„ìš”!\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: MultiModalPredictor.fit() got an unexpected keyword argument 'resume'"
     ]
    }
   ],
   "source": [
    "predictor = MultiModalPredictor(\n",
    "    label='label',\n",
    "    problem_type='classification',\n",
    "    path='C:/Users/FOR/Deep Learning/autogluon_output_best2'\n",
    ")\n",
    "\n",
    "# ì´ì–´ì„œ í•™ìŠµ (checkpoint ìë™ ê°ì§€)\n",
    "predictor.fit(\n",
    "    train_data=train_df,\n",
    "    tuning_data=val_df,\n",
    "    hyperparameters={'model': {'max_epochs': 2}},\n",
    "    presets='high_quality',\n",
    "    time_limit=3600,\n",
    "    resume=True  # ë°˜ë“œì‹œ í•„ìš”!\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b696b70d-7f69-4cec-abaf-59bf1b492fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "test_df['image'] = test_df['img_path']\n",
    "\n",
    "# 8. ì˜ˆì¸¡\n",
    "preds = predictor.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2ab638-bf81-408a-bc7f-33a7ef2fe4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "submission = pd.read_csv('open/sample_submission.csv')\n",
    "submission['rock_type'] = preds\n",
    "submission.to_csv('submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cb1f0c-58f6-4d98-9821-3ef917d4327a",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "raw",
   "id": "10da04c4-25e7-4954-afae-586d4bdcce3e",
   "metadata": {},
   "source": [
    "from autogluon.multimodal import MultiModalPredictor\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# ì„¤ì •\n",
    "train_dir = 'open/train'\n",
    "test_csv_path = 'open/test.csv'\n",
    "output_dir = 'autogluon_output_best'\n",
    "resume = True  # Trueë¡œ ë‘ë©´ ì¤‘ë‹¨ í›„ ì´ì–´ì„œ í•™ìŠµ\n",
    "\n",
    "# 1. í•™ìŠµ ë°ì´í„° êµ¬ì„±\n",
    "all_img_paths = list(Path(train_dir).rglob(\"*/*.jpg\"))\n",
    "df = pd.DataFrame({'img_path': [str(p) for p in all_img_paths]})\n",
    "df['label'] = df['img_path'].apply(lambda x: Path(x).parent.name)\n",
    "df = df.rename(columns={'img_path': 'image'})  # ì»¬ëŸ¼ëª… ë³€ê²½\n",
    "\n",
    "# 2. ê° í´ë”ì—ì„œ 7ì²œ ì¥ì˜ ë°ì´í„°ë¥¼ ëœë¤ ì¶”ì¶œ\n",
    "df_balanced = pd.DataFrame()\n",
    "for label in df['label'].unique():\n",
    "    label_df = df[df['label'] == label]\n",
    "    label_df_sampled = label_df.sample(n=7000, random_state=41)\n",
    "    df_balanced = pd.concat([df_balanced, label_df_sampled], axis=0)\n",
    "\n",
    "# 3. train/val ë¶„ë¦¬\n",
    "train_df, val_df = train_test_split(df_balanced, test_size=0.3, stratify=df_balanced['label'], random_state=41)\n",
    "train_df_small = train_df.sample(n=min(49000, len(train_df)), random_state=41)\n",
    "val_df_small = val_df.sample(n=min(15000, len(val_df)), random_state=41)\n",
    "\n",
    "# 4. GPU ì„¤ì •\n",
    "#num_gpus = 1 if torch.cuda.is_available() else 0\n",
    "\n",
    "# 5. ê¸°ì¡´ predictor ë¶ˆëŸ¬ì˜¤ê¸° ë˜ëŠ” ìƒˆë¡œ ìƒì„±\n",
    "if resume and os.path.exists(os.path.join(output_dir, 'predictor.pkl')):\n",
    "    print(\"ğŸ” ì´ì „ í•™ìŠµ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\")\n",
    "    predictor = MultiModalPredictor.load(output_dir)\n",
    "else:\n",
    "    print(\"ğŸ†• ìƒˆë¡œìš´ predictorë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
    "    predictor = MultiModalPredictor(\n",
    "        label='label',\n",
    "        problem_type='classification',\n",
    "        path=output_dir,\n",
    "        #num_gpus=num_gpus\n",
    "    )\n",
    "\n",
    "# 6. í•™ìŠµ ì‹œì‘ (ë‚¨ì€ ì—í¬í¬ë§Œí¼)\n",
    "predictor.fit(\n",
    "    train_data=train_df_small,\n",
    "    tuning_data=val_df_small,\n",
    "    epochs=3,  # ì´ í•™ìŠµí•˜ê³  ì‹¶ì€ ì—í¬í¬ ìˆ˜ (ì¤‘ë‹¨ ì „ í¬í•¨í•´ì„œ ê³„ì‚°í•´ì•¼ í•¨)\n",
    "    hyperparameter_tune_kwargs=None,\n",
    "    presets='high_quality',\n",
    ")\n",
    "\n",
    "# 7. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "test_df['image'] = test_df['img_path']\n",
    "\n",
    "# 8. ì˜ˆì¸¡\n",
    "preds = predictor.predict(test_df)\n",
    "\n",
    "# 9. ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "submission = pd.read_csv('open/sample_submission.csv')\n",
    "submission['rock_type'] = preds\n",
    "submission.to_csv('submission2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4df1069-6733-40ab-beea-5e40137da5cb",
   "metadata": {},
   "source": [
    "ğŸ” ì´ì–´ì„œ í•™ìŠµí•˜ë ¤ë©´?\n",
    "1. ì²˜ìŒ ì‹¤í–‰\n",
    "resume=Trueì´ì§€ë§Œ predictor.pklì´ ì—†ìœ¼ë©´ ìƒˆë¡œ í•™ìŠµ ì‹œì‘\n",
    "\n",
    "2. í•™ìŠµ ì¤‘ ì¤‘ë‹¨ (ì˜ˆ: ì—í¬í¬ 1ë§Œ ëë‚˜ê³  ì¢…ë£Œë¨)\n",
    "3. ë‹¤ì‹œ ì‹¤í–‰\n",
    "predictor.pkl ì¡´ì¬ â†’ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "ë‹¤ì‹œ predictor.fit() í˜¸ì¶œí•˜ë©´ ì´ì–´ì„œ í›ˆë ¨í•¨ (ë‹¨, ì´ ì—í¬í¬ ìˆ˜ëŠ” ì‚¬ìš©ìê°€ ìˆ˜ë™ ì¡°ì •í•´ì•¼ í•¨)\n",
    "\n",
    "ì˜ˆ:\n",
    "\n",
    "ì²˜ìŒì— 1 ì—í¬í¬ë§Œ í•™ìŠµí•¨\n",
    "\n",
    "ë‹¤ìŒì— ë‹¤ì‹œ ì‹¤í–‰í•  ë• epochs=2ë¡œ ë‘ë©´ 1 + 2 = ì´ 3ë²ˆ í•™ìŠµë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c238563d-0c45-48eb-acc7-44de669f3197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6876e51d-f15e-4c96-a46f-3e2e9531f38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu126\n",
      "CUDA available: True\n",
      "CUDA version: 12.6\n",
      "GPU name: NVIDIA GeForce GTX 1660 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abea1c91-b83a-4cb1-9972-9a0a840703fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import autogluon.multimodal\n",
    "print(autogluon.multimodal.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5ac9fe-3ecd-4fc7-aaf1-86eb721af8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
